# Manifesto
### Just a document outlining my approach, philosophy and justifications for some stuff in this project. Kinda like long-form comments you might find in-code but more broad.

This is a single threaded webserver Im writing/wrote to serve my personal website. It's not really meant to compete with nginx or apache, its mostly an experiment and to flex on employers by serving my CV on a from-scratch custom webserver. Since its only meant to server static pages (with front-end JS) and is not really supposed to have any actual back-end processing outside of request processing, it only accepts GET requests. Maybe in the future I'll include rudimentary backend processing should I need it for some reason.

**Why single threaded?** For the same reason I wrote a webserver to begin with: its not what youre "supposed" to do. Webservers are almost always brought up as prime examples of multi-threading in the real world. Now, I'm absolutely not against multi-threading, infact for webservers it is *significantly* better than a single-thread program. But then again, using nginx or apache is also significantly better than writing your own (non-compliant) webserver. I did it because I can, and because I thought it would be fun.

It uses `poll()` for its scheduling, essentially servicing the first connection it is able to. I could've (and some might say should've) used `epoll()` or `ppoll()`, but those aren't posix standard syscalls and therefore less portable. Why does that matter? It doesn't, its just an arbitrary standard I set for myself because I thought it would be interesting. You might be noticing a pattern in the high-level design choices at this point.

When a request comes in (post-handshake etc) it first gets parsed into struct `http_request` by `parse_http_request()` which is primarily driven by strtok. This is where most segfault errors will originate. The function only seeks to extract the method, the path, the host and the connection fields, as this is the only ones that this server needs to process and return a response. Everything else is ignored and eventually discarded. This, in connection withthe connection details stored in `ll_node` are used to populate a `http_response` and sent back to the client. Connections are always closed by the server once one receive/send transaction is complete. This may change in the future. I strongly suspect clients closing connections prematurely can cause segfault errors too.

As eluded to in the previous paragraph, connections are stored in a (singly) linked-list. It's easier this way to process connections and delete them from the pool of connections. At the moment all of these nodes are allocated with `malloc()` but I eventually want to replace it with [sas_alloc](https://github.com/SamBkamp/sas_alloc) which is a fixed-type memory allocator that I wrote; for not other reason than it inreases my flex-factor.

When a client requests a resource, the mime-type returned is parsed by a very rudimentary function that simply returns the file extension of the file. This is then concatonated with "text/". This works well enough for html, css and txt files (though I think that last one is probably undefined and browser specific). This will change at some point soon. Files are also loaded lazily; The only files loaded on start are the 404 and 500 error pages, which come default with the repo. Though, once files are loaded, they are stored in memory for faster retrieval. The system is currently limited to 20 open files at once and once it runs out it simply overwrites the first file. This isn't good, I know. I plan to change the file cache data structure anyway though so this should only be temporary (famous last words).

Files are loaded into memory with `mmap()`. This is unusual, but rather than me being contrarian, I have a justification for this one. The downside is obvious: regardless of how large the file is, you must allocate memory in blocks of 4kb (on most systems). This can lead to lots of memory being wasted unused, however mmap has two advantages that im trying to take advantage of:

1) `malloc()` has a lot of overhead and imo isn't a good fit for memory that is only loaded once and never free'd (they get free'd when the process ends), This makes it quite slow compared to say, stack allocation (which has its own obvious scoping problems).
2) loading a file with `mmap()` happens entirely in kernel space, making it insanely fast. Just stupid fast.

